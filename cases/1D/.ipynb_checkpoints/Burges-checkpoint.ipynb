{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.io\n",
    "\n",
    "# Seeds\n",
    "torch.manual_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PINNs\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    def closure():\n",
    "        optimizer.zero_grad()                                                     # Optimizer\n",
    "        loss_pde = model.loss_pde(x_int)                                    # Loss function of PDE\n",
    "        loss_ic = model.loss_ic(x_ic, u_ic)   # Loss function of IC\n",
    "        loss = loss_pde + 10*loss_ic                                          # Total loss function G(theta)\n",
    "\n",
    "        # Print iteration, loss of PDE and ICs\n",
    "        print(f'epoch {epoch} loss_pde:{loss_pde:.8f}, loss_ic:{loss_ic:.8f}')\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    # Optimize loss function\n",
    "    loss = optimizer.step(closure)\n",
    "    loss_value = loss.item() if not isinstance(loss, float) else loss\n",
    "    # Print total loss\n",
    "    print(f'epoch {epoch}: loss {loss_value:.6f}')\n",
    "    \n",
    "# Calculate gradients using torch.autograd.grad\n",
    "def gradients(outputs, inputs):\n",
    "    return torch.autograd.grad(outputs, inputs,grad_outputs=torch.ones_like(outputs), create_graph=True)\n",
    "\n",
    "# Convert torch tensor into np.array\n",
    "def to_numpy(input):\n",
    "    if isinstance(input, torch.Tensor):\n",
    "        return input.detach().cpu().numpy()\n",
    "    elif isinstance(input, np.ndarray):\n",
    "        return input\n",
    "    else:\n",
    "        raise TypeError('Unknown type of input, expected torch.Tensor or ' \\\n",
    "                        'np.ndarray, but got {}'.format(type(input)))\n",
    "\n",
    "# Initial conditions\n",
    "def IC(x):\n",
    "    N = len(x)\n",
    "    u_init = np.zeros((x.shape[0]))                                                # u - initial condition\n",
    "    # rho, p - initial condition\n",
    "    for i in range(N):\n",
    "            u_init[i] = -np.sin(np.pi*x[i])\n",
    "    return u_init\n",
    "\n",
    "# Generate Neural Network\n",
    "class DNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.net = nn.Sequential()                                                  # Define neural network\n",
    "        self.net.add_module('Linear_layer_1', nn.Linear(2, 30))                     # First linear layer\n",
    "        self.net.add_module('Tanh_layer_1', nn.Tanh())                              # First activation Layer\n",
    "\n",
    "        for num in range(2, 5):                                                     # Number of layers (2 through 7)\n",
    "            self.net.add_module('Linear_layer_%d' % (num), nn.Linear(30, 30))       # Linear layer\n",
    "            self.net.add_module('Tanh_layer_%d' % (num), nn.Tanh())                 # Activation Layer\n",
    "        self.net.add_module('Linear_layer_final', nn.Linear(30, 1))                 # Output Layer\n",
    "\n",
    "    # Forward Feed\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    # Loss function for PDE\n",
    "    def loss_pde(self, x):\n",
    "        y = self.net(x)                                                # Neural network\n",
    "        u = y[:, 0:1]\n",
    "        \n",
    "        U = u**2/2\n",
    "        \n",
    "        #F1 = U2\n",
    "        \n",
    "        # NN_{rho}, NN_{u}, NN_{p}\n",
    "        gamma = 1.4                                                    # Heat Capacity Ratio\n",
    "\n",
    "        # Gradients and partial derivatives\n",
    "        dU_g = gradients(U, x)[0]                                  # Gradient [rho_t, rho_x]\n",
    "        U_x = dU_g[:, 1:]\n",
    "        du_g = gradients(u, x)[0]                                  # Gradient [rho_t, rho_x]\n",
    "        u_t,u_x = du_g[:, :1],du_g[:,1:]\n",
    "        d =  0.1*(abs(u_x)-u_x\n",
    "\n",
    "\n",
    "        f = (((rho_t + U2_x)  + 1)**2).mean() + \\\n",
    "            (((U2_t  + F2_x)  + 1)**2).mean() + \\\n",
    "            (((U3_t  + F3_x)  + 1)**2).mean()# + \\\n",
    "           # 0.1*((abs(eta_t+phi_x)+eta_t+phi_x)).mean()   + \\\n",
    "           # (abs(rho_t)).mean() + (abs(U3_t)).mean() # \n",
    "        #f = (((rho_t + U2_x))**2).mean() + \\\n",
    "        #    (((U2_t  + F2_x))**2).mean() + \\\n",
    "        #    (((U3_t  + F3_x))**2).mean()# + \\\n",
    "         #   (abs(rho_t)).mean() + (abs(U3_t)).mean() # \n",
    "            #0.1*((abs(eta_t+phi_x)+eta_t+phi_x)).mean() \n",
    "            #((abs(rho)-rho)**2).mean() + 0.1*((abs(U3) - U3)**2).mean() \n",
    "          #  ((min(rho,0))**2).mean() + 0.1*((min(U3,0))**2).mean() +\\\n",
    "            \n",
    "\n",
    "       # f = (((rho_t + U2_x))**2).mean() + \\\n",
    "       #     (((U2_t  + F2_x))**2).mean() + \\\n",
    "       #     (((U3_t  + F3_x))**2).mean() + \\ \n",
    "       #     0.1*((abs(eta_t+phi_x)+eta_t+phi_x)).mean() \n",
    "       #     ((rho*(u_t + (u)*u_x) + (p_x))**2).mean() + \\\n",
    "       #     ((p_t + gamma*p*u_x + u*p_x)**2).mean()\n",
    "          #  ((U3_t  + F3_x)**2).mean()\n",
    "\n",
    "        return f\n",
    "\n",
    "    # Loss function for initial condition\n",
    "    def loss_ic(self, x_ic, rho_ic, u_ic, p_ic):\n",
    "        y_ic = self.net(x_ic)                                                      # Initial condition\n",
    "        rho_ic_nn, p_ic_nn,u_ic_nn = y_ic[:, 0], y_ic[:, 1], y_ic[:, 2]            # rho, u, p - initial condition\n",
    "\n",
    "        # Loss function for the initial condition\n",
    "        loss_ics = ((u_ic_nn - u_ic) ** 2).mean() + \\\n",
    "               ((rho_ic_nn- rho_ic) ** 2).mean()  + \\\n",
    "               ((p_ic_nn - p_ic) ** 2).mean()\n",
    "\n",
    "        return loss_ics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
